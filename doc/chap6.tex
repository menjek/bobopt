\chapter{Yield complex method}
\label{yield-intro}
The Bobox scheduler is a cooperative scheduler, thus it inherits its behavior. The efficiency of programs running in a parallel environment with cooperative scheduling tightly depends on user code. A task must finish or give up its execution in order to execute a different task on the same CPU. If tasks depend on each other in some way, they should keep balanced execution times as much as possible. Furthermore, too little execution times cause that scheduling exceeds the \textit{real} execution in the CPU consumption\footnote{The prefetch optimization method described in the previous chapter aims to reduce a number of such executions.}, big execution times can inhibit parallelism by keeping dependent tasks out of an execution. Big execution times of tasks producing data can also congest framework internal structures.

This optimization method aims to resolve big execution times. The main goal is to detect complex tasks and yield their execution in appropriate places in code. Listing~\ref{yield-signature} contains the signature of the \code{basic\_box} member functions for such purpose.

\begin{lstlisting}[caption={The signature of the yield execution function.}, label={yield-signature}]
void yield();
\end{lstlisting}

\section{Complexity}
\label{yield-complexity}
There are multiple ways to measure the code complexity. Ideally, if we know input data, we run a program with this data and measure its performance. This process is called \emph{profiling}. The quality of optimizations based on profiling is very high, but it requires human resources to analyse data and update code\footnote{Most popular compilers provide a feature for optimizations based on profiling data, \emph{Profile Guided Optimizations (PGO)}~\cite{pgo}, but this approach cannot replace the higher level look on algorithms used in an application provided by a programmer.}. There are various techniques used for measurements such as statistical sampling with the hardware support which is very fast, or instrumentation which is more intrusive thus affecting an application performance, but given information is more precise. Instrumentation is useful for applications with a repetitive step with a limit for minimum execution time, or to keep execution times of a step as stable as possible. It helps to find cause of spikes. Such applications are computer games, many sorts of simulations or GUI applications.

Another approach for measuring the complexity is to compile code and consider the number of generated instructions as the magnitude of the complexity. This assumption is naive and imprecise. The main source of the complexity in most applications comes from loops, repeatedly executed code paths, and this information is not present in such metric. For snippets of code without a loop, this method is precise enough even if there are multiple execution paths. In bigger code samples, there is probably a bigger amount of loops, thus code is more complex, but the number of instructions reflects it less and less precise.

The complexity can be also measured based on an indentation in source code. A bigger maximal indentation usually means more complex code. This approach makes assumptions about a source code formatting. Its preciseness tightly depends on these assumptions and how source code follows them.

Company programming rules often contain a rule related to the concept called \emph{cyclomatic complexity}~\cite{cyclomatic-complexity}. It measures the logical complexity, the number of linearly independent paths through code. This optimization method aims to reduce a different kind of the code complexity. More code branches decreases readability for a human, but it has almost no effect on runtime.

\section{Control flow graph}
\label{yield-cfg}
The optimizer has to be able to estimate the complexity of all paths in the control flow graph passing through every graph node representing a code block to find the proper place for a call to the yield member function. The goal is to \textit{cut} long execution paths exceeding some predefined threshold. For simplification, the analyser assumes that all paths have the same probability. Since multiple execution paths often pass through a specific code block represented by a graph node, the insertion of the yield call into this code block cuts all paths passing through this block. In other words, in order to reduce execution time of a single path, such action can cause too little execution times for some other paths. The benefit can be lower than the cost.

Figure~\ref{yield-wrong1} shows an example of the described situation. The single long execution path is the thinner dashed curved path. Thicker lines represent multiple short execution paths. The yielded block cuts many short paths in order to get rid off the single long path. More short paths mean a lower probability of the long path being taken, thus a lower probability of the optimization benefit. Furthermore, it causes more scheduling so it can even slow down the overall performance.

\begin{figure}[h!]
\caption{An example of a wrong yield placement into a block shared by multiple short paths and a single long path.}
\label{yield-wrong1}
\centering
\vspace{0.5cm}
\begin{tikzpicture}[node distance=2.25cm]
	% Styles
	%\tikzstyle{cut} = [circle, minimum width=5pt, fill, inner sep=0pt]
	\tikzstyle{cut} = [rectangle, inner sep=0pt]

	% Code blocks
	\node(entry){Entry};
	\node[cut, below of= entry](cut){yield};
	\node[below of= cut](exit){Exit};
	
	\path[pil, very thick] (entry) 	edge[left] node {\textbf{many} short} (cut)
	           (cut) 	edge[right] node {\textbf{many} short} (exit);
	           
	\path[pil, very thin, dashed]  (entry) 	edge[bend left=85, right] node {long} (cut)
	           (cut) 	edge[bend right=85, left] node {long} (exit);
\end{tikzpicture}
\end{figure}

\subsection{Block complexity}
In order to measure complexities of paths in CFG, the optimizer must be able to measure the complexity of the basic construction element of a path, a code block. Only single execution path passes through a code block. Statements in a code block are executed one by one. When a control flow enters a block, if no exception occurs, each statement is executed exactly once until the control flow exits the block. For such code block, the best approach to measure the complexity is an approach similar to measuring the complexity of code by the number of generated instructions, see the second paragraph in Section~\ref{yield-complexity}.

Code blocks consist of statements. Most statements generate zero or more instructions with constant execution time. Problematic statements are call expressions, because they effectively transfer an execution out of CFG. Their complexity is unknown. The used solution is to estimate their complexity and assign fixed values for different types of call expressions. A block complexity is then a sum of complexities of all statements in this block using values from Table~\ref{yield-block}. The value is searched from the top to the bottom of the table for the first matching row. Trivial, constant and inline call expressions create a subset of call expressions which create a subset of statements. The tool allows a user to change all values by providing a custom configuration. Since trivial call expressions generate no instructions, their default complexity is zero. A compiler evaluates constant call expressions during a compilation and does not generate any instructions for them, thus their default complexity is also zero. The complexity of inlined functions and the rest of call expressions cannot be stated precisely. Even though complexities of such functions vary, their values are very probably in some reasonable sized range. Values for inlined call expressions and the rest of call expressions in Table~\ref{yield-block} were calculated based on statistics gathered from a code used in benchmarks, see Chapter~\ref{results}. The function complexity is calculated simply as a number of statements in its body. Appendix~C contains complete statistics of measured functions complexities.

\begin{table}[h!]
\caption{Complexities of statements in a block.}
\label{yield-block}
\vspace{0.1cm}
\renewcommand{\arraystretch}{1.1}
\centering
\begin{tabular}{ l | r }
  \textbf{Trivial call expression}\\A function body does not generate any instruction, the body is empty. & 0 \\
  \textbf{Constant call expression}\\A function defined as a constant expression. & 0 \\
  \textbf{Inlined call expression}\\A function is decided to be inlined by the compiler. & 10 \\
  \cellcolor[gray]{0.9}\textbf{Call expression} & \cellcolor[gray]{0.9}40 \\
  \cellcolor[gray]{0.75}\textbf{Statement} & \cellcolor[gray]{0.75}1 \\
\end{tabular}
\end{table}

\subsection{Path complexity}
A code block is the basic construction element of a code path. With the definition of the code block complexity, it is possible to define a code path complexity as well. Every CFG constructed in Clang analyzer contains two specially designed empty blocks, i.e., \emph{Entry} and \emph{Exit} blocks. Control flow enters a graph through the \emph{Entry} block and leaves a graph through the \emph{Exit} block. However, if there are loops in CFG, there is an infinite number of paths from \emph{Entry} to \emph{Exit} blocks.

Therefore, loop bodies are evaluated as independent CFG making source CFG acyclic. When a path enters a node with a loop statement as a terminator, this path creates a new path for every path in the loop body. The path that skips a loop body is omitted from the analysis. This path has a very low probability, but it affects results significantly. New paths behave as they skip a loop body, but their complexity is a sum of the source path complexity, block complexity and body path complexity multiplied by a predefined constant from Table~\ref{yield-loop-const}. The optimizer allows users to provide their custom values using a custom configuration. Values in Table~\ref{yield-loop-const} were calculated based on tool code and its execution on code used in benchmarks, see Chapter~\ref{results}. Appendix~C contains measurements of loop body executions for all \code{for} loops and all \code{while} loops. Basically, values in Table~\ref{yield-loop-const} are averages of an average number of loop body executions.

\begin{table}[h!]
\caption{Multipliers for loop body complexities.}
\label{yield-loop-const}
\vspace{0.1cm}
\renewcommand{\arraystretch}{1.1}
\centering
\begin{tabular}{ m{5cm} | r }
  \code{for} statement & 5 \\
  \code{while} statement & 15 \\
\end{tabular}
\end{table}

Figure~\ref{yield-loop} shows an example of a part of CFG with a \code{for} loop statement and an \code{if} selection statement in the body of this loop, see Listing~\ref{yield-loopcode} for C++ code. Numbers next to edges represent paths complexities and numbers in graph nodes represent blocks complexities. There is a single path with the complexity of 5 entering the node with the \code{for} statement terminator. The loop body itself contains two different paths with complexities of 2 and 3. Two paths leaving the block with the \code{for} statement terminator have complexities of 16 and 21. The calculation for those paths is \emph{the \code{for} loop multiplier * the body path complexity + the entering path complexity + the complexity of the block with the \code{for} statement terminator}, see Equations (\ref{equation-1}) and (\ref{equation-2}) for paths leaving the \code{for} statement from Figure~\ref{yield-loop}.

\begin{equation}
\label{equation-1}
(5 * 2) + 5 + 1 = 16
\end{equation}
\begin{equation}
\label{equation-2}
(5 * 3) + 5 + 1 = 21
\end{equation}

\begin{lstlisting}[caption={A loop statement and a selection statment in a loop body.}, label={yield-loopcode}]
...
for (...)
{
    if (/* the complexity is 1 */)
    {
        /* the complexity is 2 */
    }
    else
    {
        /* the complexity is 1 */
    }
}
...
\end{lstlisting}

\begin{figure}[h!]
\centering
\vspace{0.5cm}
\begin{tikzpicture}[node distance=3.5cm]
	\tikzstyle{node} = [circle, draw, minimum width=17pt, inner sep=0pt]

	% Loop node
	\node[node](loop){1};
	\node[above right of=loop](entry){};
	\node[below right of=loop](exit){};
	
	\path[pil] (entry) edge[right] node {5} (loop)
	           (loop) edge[right] node {16, 21} (exit);
	
	\node[left of=loop, xshift=1.0cm](body){};
	\node[node, below of=body, yshift=2.0cm](b-entry){1};
	\node[node, above of=body, yshift=-2.0cm](b-exit){0};
	\node[node, left of=body, xshift=2.35cm](b1){1};
	\node[node, right of=body, xshift=-2.35cm](b2){2};
	
	\path[pil] (loop) edge[bend left=50, below] node {0} (b-entry)
	           (b-exit) edge[bend left=50, above] node {2, 3} (loop);
	           
	\path[pil] (b-entry) edge[bend left=20, left] node {1} (b1)
	           (b-entry) edge[bend right=20, right] node {1} (b2);
	           
	\path[pil] (b1) edge[bend left=20, left] node {2} (b-exit)
	           (b2) edge[bend right=20, right] node {3} (b-exit);
	
\end{tikzpicture}
\caption{A path passing through a node with the \code{for} statement terminator and a selection statement in its body, see Listing~\ref{yield-loopcode} for the code example.}
\label{yield-loop}
\end{figure}

\subsection{Quality of CFG}
\label{yield-quality}
Briefly, the algorithm to reduce a number of complex paths tries to inject the yield function call into some CFG block to make it \textit{better} than source CFG. Such algorithm needs a value to quantify the CFG quality to compare source and result graphs.

The goal of this optimization method is to reduce a number of complex paths in long-running tasks. For simplification, any path with complexity bigger than some predefined constant is considered to be too complex. Figure~\ref{yield-penalty} shows one approach for the CFG quality evaluation. The top horizontal line represents either \emph{Entry} block or a block with the yield call expression, i.e., a block where a control flow enters CFG. Vertical lines represent different paths and line lengths represent paths complexities. The \emph{threshold} horizontal line represents the constant complexity value to distinguish too complex paths. Parts of paths exceeding a threshold are highlighted. Thus, the goal is to minimize the length of highlighted parts of paths. The highlighted part of a path exceeding a threshold is called \emph{penalty}.

\begin{figure}[h!]
\centering
\caption{The \emph{penalty} approach to evaluate a CFG quality.}
\label{yield-penalty}
\vspace{0.5cm}
\begin{tikzpicture}[node distance=2.0cm]
	
	\node(paths) at (0,0.5) {Paths};
	
	% Base
	\node(entry) at (-6.25,0) {\emph{Entry}/yield};
	\draw[line width=3pt] (-5,0) -- (5,0);
	
	% Threshold
	\node[below=of entry.east, anchor=east] (threshold) {Threshold};
	\draw[line width=1pt] (-5,-2) -- (5,-2);

	% Penalty	
	\node[below=of threshold.east, anchor=east, yshift=0.75cm] (penalty) {Penalty};

	% Tasks
	\draw[thick] (-4,0) -- (-4,-1.6);
	\draw[thick] (-3,0) -- (-3,-2.75);
	\draw[pattern=north west lines, pattern color=gray] (-3.1,-2.0) rectangle (-2.9,-2.75);
	\draw[thick] (-2,0) -- (-2,-2.23);
	\draw[pattern=north west lines, pattern color=gray] (-2.1,-2.0) rectangle (-1.9,-2.23);
	\draw[thick] (-1,0) -- (-1,-0.3);
	\draw[thick] ( 0,0) -- ( 0,-4.0);
	\draw[pattern=north west lines, pattern color=gray] (-0.1,-2.0) rectangle ( 0.1,-4.0);
	\draw[thick] ( 1,0) -- ( 1,-5.0);
	\draw[pattern=north west lines, pattern color=gray] ( 0.9,-2.0) rectangle ( 1.1,-5.0);
	\draw[thick] ( 2,0) -- ( 2,-1.75);
	\draw[thick] ( 3,0) -- ( 3,-1.1);
	\draw[thick] ( 4,0) -- ( 4,-4.2);
	\draw[pattern=north west lines, pattern color=gray] ( 3.9,-2.0) rectangle ( 4.1,-4.2);
\end{tikzpicture}
\end{figure}

When the algorithm to reduce a number of complex paths places a call to the yield function into some block, it cuts one or more paths. A new call to the yield function adds a work for the scheduler and does not remove any work from a task. Thus, a number of new calls to the yield function should be minimized. Unfortunately, there are situations when a placement of the yield function call is equally good for multiple CFG blocks. The simple situation with a single path exceeding a threshold by a single statement is an example. The algorithm can place a call to the yield function into any block passed by this path and it would minimize its penalty to zero. In some edge scenarios, the algorithm could potentially cut only the last statement of the path. It is not the desired behavior since one statement cannot inhibit parallelism significantly. The path should be cut close to its middle or not at all if the yield function call affects other paths negatively.

The solution is to take also other paths than only those too complex into an account in the CFG quality evaluation. Then, the algorithm calculates a sum of distances of path complexities from a threshold value, see Figure~\ref{yield-distance}. This approach takes into an account also the disadvantage of placing the yield call expression into some block. The optimizer achieves very good results with such metric of the CFG quality.

\begin{figure}[h!]
\caption{The \emph{distance from threshold} approach to evaluate the CFG quality.}
\label{yield-distance}
\centering
\vspace{0.5cm}
\begin{tikzpicture}[node distance=2.0cm]
	
	\node(paths) at (0,0.5) {Paths};
	
	% Base
	\node(entry) at (-6.25,0) {\emph{Entry}/yield};
	\draw[line width=3pt] (-5,0) -- (5,0);
	
	% Threshold
	\node[below=of entry.east, anchor=east] (threshold) {Threshold};
	\draw[line width=1pt] (-5,-2) -- (5,-2);

	% Tasks
	\draw[thick] (-4,0) -- (-4,-1.6);
	\draw[pattern=north west lines, pattern color=gray] (-4.1,-1.6) rectangle (-3.9,-2.0);
	\draw[thick] (-3,0) -- (-3,-2.75);
	\draw[pattern=north west lines, pattern color=gray] (-3.1,-2.0) rectangle (-2.9,-2.75);
	\draw[thick] (-2,0) -- (-2,-2.23);
	\draw[pattern=north west lines, pattern color=gray] (-2.1,-2.0) rectangle (-1.9,-2.23);
	\draw[thick] (-1,0) -- (-1,-0.3);
	\draw[pattern=north west lines, pattern color=gray] (-1.1,-0.3) rectangle (-0.9,-2.0);
	\draw[thick] ( 0,0) -- ( 0,-4.0);
	\draw[pattern=north west lines, pattern color=gray] (-0.1,-2.0) rectangle ( 0.1,-4.0);
	\draw[thick] ( 1,0) -- ( 1,-5.0);
	\draw[pattern=north west lines, pattern color=gray] ( 0.9,-2.0) rectangle ( 1.1,-5.0);
	\draw[thick] ( 2,0) -- ( 2,-1.75);
	\draw[pattern=north west lines, pattern color=gray] ( 1.9,-1.75) rectangle ( 2.1,-2.0);
	\draw[thick] ( 3,0) -- ( 3,-1.1);
	\draw[pattern=north west lines, pattern color=gray] ( 2.9,-1.1) rectangle ( 3.1,-2.0);
	\draw[thick] ( 4,0) -- ( 4,-4.2);
	\draw[pattern=north west lines, pattern color=gray] ( 3.9,-2.0) rectangle ( 4.1,-4.2);
\end{tikzpicture}
\end{figure}

\subsection{Additional data structures in optimizer}
\label{yield-data}
The analyser needs to keep additional data to CFG when calculating paths complexities. Fortunately, each block in CFG has a unique identifier. Additional data for each block is stored in a map with a block identifier as the key.

Data about every path is stored for every block it passes. Every path has its own unique identifier. Because many paths share their beginnings, information about their complexities from the \emph{Entry} block to a block they pass is shared between these paths in the structure called \code{path\_data\_type} with:

\begin{itemize}
\item{Set of path identifiers.}
\item{Complexity.}
\end{itemize}
Block data consists of:
\begin{itemize}
\item{Set of \code{path\_data\_type} structures.}
\item{A yield state of a block with three different states:}
	\begin{description}
	\item[No]{There is no yield call expression in this block.}
	\item[Planned]{The optimizer plans to put yield into this block.}
	\item[Present]{Source code already includes the yield call expression.}
	\end{description}
	\emph{Note}: Distinguish between \emph{Present} and \emph{Planned} states is to simplify the final code transformation.
\item{A map of a path identifier as the key and the complexity as a value for blocks with a loop statement terminator. A map holds complexities of loop body paths.}
\end{itemize}

This data is an input for the CFG quality evaluation. The optimization algorithm changes yield states of blocks to the \emph{Planned} state in order to increase the CFG quality.

\subsection{Optimization algorithm}
With a metric for the CFG quality, it is possible to describe the algorithm for the yield complex optimization formally and in more details, see Figure~\ref{yield-algorithm}. The algorithm runs the optimization step on CFG until this optimization step returns CFG with a better quality. The \emph{distance} variable is a sum of distances of paths complexities from a threshold value, a metric described in Section~\ref{yield-quality}. The algorithm tries to minimize this distance value. The optimization step places zero or one yield into data representing CFG. Data returned from the optimization step is then evaluated and tested whether its quality increased.

\begin{figure}[h!]
\caption{The algorithm for the yield complex optimization method.}
\label{yield-algorithm}
\begin{enumerate}
\item{\emph{cfg} = Build CFG data.}
\item{\emph{distance} = Calculate the quality of \emph{cfg}.}
\item{\emph{temp\_cfg} = Run the optimization step on \emph{cfg}.}
\item{\emph{temp\_distance} = Calculate the quality of \emph{temp\_cfg}.}
\item{If \emph{temp\_distance} < \emph{distance} then}
	\begin{enumerate}[label=5.\arabic*.]
	\item{\emph{distance} = \emph{temp\_distance}.}
	\item{Swap \emph{cfg} with \emph{temp\_cfg}.}
	\item{Continue in the step 3.}
	\end{enumerate}
\item{Else finish, \emph{cfg} is optimized.}
\end{enumerate}
\end{figure}

\pagebreak[4]

\subsubsection{Complexities calculation and quality evaluation}
The optimizer uses the depth-first search algorithm to analyse CFG and calculate complexities. The analysis has to handle yield calls in blocks, which are already in code or are planned for an insertion by the optimizer. Inputs of the analysis are CFG and data structures described in Section~\ref{yield-data}. The CFG quality evaluation gets paths and their complexities as an input and calculates a value representing the CFG quality described in Section~\ref{yield-quality}.

\subsubsection{Optimization step}
The only goal of the optimization step is to decrease the distance value representing the quality of CFG. The optimizer uses brute force to achieve the goal. Firstly, it collects all blocks where at least one path ends, i.e., the \textit{Exit} block and blocks with the \emph{Planned} or the \emph{Present} yield state. Then, it processes every block with at least one path with complexity higher than the threshold value and calculates what happens if the yield call expression is placed into that block. A block with the best outcome has its yield state set to \emph{Planned}.

The complexity of such algorithm tightly depends on the complexity of user code and on the structure of its CFG. Every block is visited twice in each optimization step. All paths complexities are recalculated\footnote{A recalculation of a path complexity means one subtraction from its complexity.} for every block with at least one path with complexity higher than the threshold value. However, the next optimization step is executed only if the previous optimization step has changed the yield state of one block into the \emph{Planned} state. Thus, the optimization step has increased a number of paths, but greatly decreased a number of blocks with too complex paths.

\subsection{Default threshold}
\label{yield-default}
A presence of loops reflects the code complexity the most. However, a loop body has to be appropriately complex to make the whole loop complex. The only non-trivial metric used in this optimization method for the complexity is again a loop. If both loops are \code{for} loops, then based on values from Tables \ref{yield-block} and \ref{yield-loop-const}, the inner loop body must be more complex than a single inlined call expression. Otherwise, the inner loop would have the complexity of 50, approximately as big as a single non-inlined call expression with the complexity of 40. I have decided for two non-inlined call expressions since only one is the minimal case and five of them is basically another inner loop with one call expression.

Using values from Tables \ref{yield-block} and \ref{yield-loop-const}, the default value for threshold is calculated as the execution of five inner \code{for} loops with two non-inlined, non-trivial, non-constant call expressions, see Equation~\ref{yield-default-eq}.

\begin{equation}
\label{yield-default-eq}
5 * 5 * 2 * 40 = 2000
\end{equation}

\subsection{Code injection}
The last step of the optimization process is the injection of the yield call expression to blocks with the \emph{Planned} yield state. A block with such yield state can be empty, it can contain a single statement in a condition expression of a selection statement, the right-hand side expression in a binary expression, the else branch in a conditional expression, or any other language structure where the C++ language grammar does not allow to chain statements.

The easy solution is to find a compound statement, where the injection of the yield call expression is as good as the injection directly to the chosen block. The injection of the yield call expression into a compound statement is then simple and safe. For reminder, the prefetch optimization method already does inject code into compound statements.

Firstly, the optimization method collects all compound statements in the function body compound statement\footnote{The function body compound statement is included in this set}. Then, the optimizer collects all blocks with the \emph{Planned} yield state. For every collected block, the optimizer checks all compound statements whether the relation of the collected block and the compound statement matches any of special cases, see Figure~\ref{yield-injection}.

\begin{enumerate}
\item{If the block with the \emph{Planned} yield state is the condition expression of the \code{if}, \code{switch} or \code{while} statement that is a child statement of the compound statement, the yield call expression is injected just before the \code{if}, \code{switch} or \code{while} statement.}
\item{If the block with the \emph{Planned} yield state is the initialization statement or the condition expression of the \code{for} statement that is a child of the compound statement, the yield call expression is injected just before the \code{for} statement.}
\item{If the block with the \emph{Planned} yield state is the incremental expression of the \code{for} statement and the compound statement is its body, the yield call expression is injected as the last statement of the compound statement.}
\end{enumerate}

\begin{figure}[h!]
\caption{The injection of the yield call for some special cases of statements.}
\label{yield-injection}
\centering
\vspace{0.5cm}
\begin{tikzpicture}[node distance=0.0cm]
	\tikzstyle{empty} = [rectangle, draw, thin, minimum width=2.0cm, minimum height=13pt, inner sep=0pt, rounded corners=3pt]
	
	\tikzstyle{yield} = [rectangle, draw, thin, minimum width=0.5cm, minimum height=13pt, inner sep=0pt, rounded corners=3pt]

	% If statement
	\node[yield](ifyield){1};
	\node[below=15pt of ifyield.west, anchor=west](ifstmt){if/switch/while (};
	\node[empty, right=of ifstmt.east, anchor=west](ifcond){ cond };
	\node[right=of ifcond.east, anchor=west](ifstmtthen){) \{\}};
	
	\path[pil] (ifcond.north) edge[bend right=5] node {} (ifyield);
	
	% for statement
	\node[yield, below=1.5cm of ifstmt.west, anchor=west](foryield){2};
	\node[below=15pt of foryield.west, anchor=west](forstmt){for (};
	
	\node[empty, right=of forstmt.east, anchor=west](forinit){ init };
	\node[right=of forinit.east, anchor=west](forinitsemi){; };
	
	\node[empty, right=of forinitsemi.east, anchor=west](forcond){ cond };
	\node[right=of forcond.east, anchor=west](forcondsemi){; };
	
	\node[empty, right=of forcondsemi.east, anchor=west](forinc){ inc };
	\node[right=of forinc.east, anchor=west](forincend){)};
	
	\node[below=15pt of forstmt.west, anchor=west](forlbracket){\{};
	\node[below=15pt of forlbracket.west, anchor=west, xshift=1cm](fordots){...};
	\node[yield, below=15pt of fordots.west, anchor=west](forbodyyield){3};
	\node[below=15pt of forbodyyield.west, anchor=west, xshift=-1cm](forrbracket){\}};
	
	\path[pil] (forinit.north) edge[bend right=15] node {} (foryield)
	           (forcond.north) edge[bend right=10] node {} (foryield)
	           (forinc.south) edge[bend left=20] node {} (forbodyyield);

\end{tikzpicture}
\end{figure}

\section{Further improvements}
\label{yield-future}
The current state of the optimization method can be still improved. Some indications about further improvements were already mentioned, e.g., producers can congest internal framework structures in the introduction of this chapter, or different path probabilities in the introduction of Section~\ref{yield-cfg}.

\subsection{Runtime checks}
If auto-vectorization back-end optimizers cannot prove that operations in a loop body do not overlap in the compilation process, they generate runtime checks and both versions of a loop, original and vectorized. Although there is nothing to \emph{prove} mentioned in the yield complex optimization method description, there is a lot of estimations such as call expression complexities or loop body multipliers. It would be possible to handle suspicious cases more precisely using runtime checks.

\subsection{Probabilities}
The optimization method considers that all paths in CFG have the same probability. It is a simplification. For example, functions often contain multiple checks of their arguments on the beginning of their bodies, but the analysis can assume that these branches will not be taken in majority of function calls because inputs are expected to be correct. What probabilities should be assigned to paths is a very complex task beyond a scope of my thesis. Developers of branch predictors on modern processors confront the similar task~\cite{branch-predictor}. Some ideas for a branch prediction could be reused for the static analysis, but most mechanisms used for predictions are based on runtime information.

\subsection{Identify producers}
There are multiple drawbacks of long-running tasks mentioned in the introduction of this chapter. One of them is the possible congestion of framework internal structures. The analysis can assign more \emph{weight} to paths that produce data for other tasks in order to ease their yield. Loops producing data deserves more recognition than loops performing calculations.

\subsection{Deep analysis}
Probably the simplest case of an improvement for the optimizer is the deeper analysis of statements in CFG blocks. Complexities of call expressions are estimated, but some of them can be calculated more precise. All categories of call expressions can be analysed deeper if the analysis has an access to the body of a callee. It would be unbearable to count in CFG of the function definition, but some heuristic based on a callee definition can be helpful. The possible result of such heuristic can be in form of the depth of the most nested loop.
