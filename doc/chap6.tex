\chapter{Yield complex method}
\label{yield-intro}
The Bobox scheduler is a cooperative scheduler so it inherits its drawbacks. An efficiency of programs running in a parallel environment with a cooperative scheduling tightly depends on user code. A task must finish or give up its execution in order to execute a different task on the same CPU. If tasks depend on each other in some way, they should keep balanced execution times as much as possible. Furthermore, too little execution times cause that scheduling exceeds the \textit{real} execution in the CPU consumption\footnote{The prefetch optimization method described in the previous chapter aims to reduce a number of such executions.}, big execution times can inhibit parallelism by keeping dependent tasks out of an execution. Big execution times of tasks producing data can also congest framework internal structures.

This optimization method aims to resolve big execution times. The main goal is to detect complex tasks and yield their execution in appropriate places in code. The \code{basic\_box} class provides the member function for this purpose, see listing \ref{yield-signature}.

\begin{lstlisting}[caption={Signature of the yield execution function.}, label={yield-signature}]
void yield();
\end{lstlisting}

Different systems can have different thresholds for a task complexity. The analysis is configurable so the optimizer can be tuned up for every system.

\section{Complexity}
\label{yield-complexity}
There are multiple ways to measure a code complexity. Ideally, if we know input data, we run a program with this data and measure. This process is called \emph{profiling}. A quality of optimizations based on profiling is very high, but it requires human resources to analyse data and update code\footnote{The most popular compilers provide the feature for optimizations based on profiling data, \emph{Profile Guided Optimizations (PGO)} \cite{pgo}, but this approach cannot replace the higher level look on algorithms used in an application provided by a programmer. Microsoft Visual Studio calls this feature \emph{Profile counts} \cite{profile-counts}.}. There are various techniques used for a measurements such as statistical sampling with the hardware support which is very fast, or instrumentation which is more intrusive thus affecting an application performance, but given information is more precise. Instrumentation is useful for applications with a repetitive step with a limit for minimum execution time, or to keep execution times of a step as stable as possible. It helps to find cause of spikes. Such applications are computer games, many sorts of simulations or GUI applications.

An another approach for measuring a complexity is to compile code and consider the number of generated instructions as a magnitude of complexity. In the end, an execution of instructions is the process that consumes CPU time. This assumption is naive and imprecise. The main source of a complexity in the most applications comes from loops, repeatedly executed code paths, and this information is not present in such metric. For snippets of code without a loop, this method is precise enough, even if there are multiple execution paths. In bigger code samples, there is a probability of a bigger amount of loops, thus code is more complex, but the number of instructions reflects it less and less precise.

Company programming rules often contain a rule related to the concept called \emph{cyclomatic complexity} \cite{cyclomatic-complexity}. It measures a logical complexity, a number of linearly independent paths through code. This optimization method aims to reduce a different kind of a code complexity. More code branches decreases readability for a human, but it has almost no effect on runtime. There are coding rules such as \emph{Use Early Exits and} \emph{\code{continue}} \emph{to Simplify Code} \cite{llvm-coding-standards} to increase readability of code with a high cyclomatic complexity.

\section{Control flow graph}
A construction of CFG from AST in Clang tools is for free from the implementation point of view. Clang static analyzer, see subsection \ref{clang-analyzer}, provides structure and the interface to build it.

\subsection{The goal of the analysis}
CFG represents all possible execution paths through source code and the goal is to \textit{cut} long execution paths exceeding some predefined threshold. For simplification, the analyser assumes that all paths have the same probability. Since multiple execution paths often pass through a specific code block represented by a graph node, the insertion of yield call into this code block cuts all paths passing through this block. In different words, in order to reduce execution time of a single path, it can cause too little execution times for some other paths, and a benefit can be lower than cost.

An example of the described situation is shown in figure \ref{yield-wrong1}. The single long execution path is the thinner curved path. Thicker lines represent multiple short execution paths. The yielded block cuts many short paths in order to get rid off the single long path. More short paths mean a lower probability of the long path being taken, thus a lower probability of the optimization benefit.

\begin{figure}[h!]
\caption{An example of a wrong yield placement into a block shared by multiple short paths and a single long path.}
\label{yield-wrong1}
\centering
\vspace{0.5cm}
\begin{tikzpicture}[node distance=2.25cm]
	% Styles
	%\tikzstyle{cut} = [circle, minimum width=5pt, fill, inner sep=0pt]
	\tikzstyle{cut} = [rectangle, inner sep=0pt]

	% Code blocks
	\node(entry){Entry};
	\node[cut, below of= entry](cut){yield};
	\node[below of= cut](exit){Exit};
	
	\path[pil, very thick] (entry) 	edge[left] node {\textbf{many} short} (cut)
	           (cut) 	edge[right] node {\textbf{many} short} (exit);
	           
	\path[pil, very thin]  (entry) 	edge[bend left=85, right] node {long} (cut)
	           (cut) 	edge[bend right=85, left] node {long} (exit);
\end{tikzpicture}
\end{figure}

!!!! MOVE !!!!
Now imagine code with the only long code path exceeding threshold multiple times. Ideally, path would be cut as many times as it exceeds threshold in the way newly created paths have approximately the same complexity. Unfortunately, algorithm works iterative way and cuts the path in the middle in the first iteration step as shown on figure \ref{yield-wrong2}.

\begin{figure}[h!]
\caption{Example of how algorithm cuts in the first step a path 3 times exceeding threshold, and ideal scenario.}
\label{yield-wrong2}
\centering
\vspace{0.5cm}
\begin{tikzpicture}[node distance=2.5cm]
	% styles
	\tikzstyle{cut} = [circle, minimum width=4pt, fill, inner sep=0pt]

	% left path
	\node[title](left-name){\emph{Source CFG}};
	
	\node[below of= left-name, yshift=1.5cm](left-entry){Entry};
	\node[below of= left-entry](left-center){};
	\node[below of= left-center](left-exit){Exit};
	
	\path[pil] (left-entry) edge[left] node {3} (left-exit);
	
	% alg path
	\node[title, right of= left-name, xshift=1.5cm](alg-name){\emph{1. step of algorithm}};
	
	\node[below of= alg-name, yshift=1.5cm](alg-entry){Entry};
	\node[cut, below of= alg-entry](alg-center){};
	\node[below of= alg-center](alg-exit){Exit};
	
	\path[pil] (alg-entry) edge[left] node {1.5} (alg-center)
	           (alg-center) edge[left] node {1.5} (alg-exit);
	           
	% ideal path
	\node[title, right of= alg-name, xshift=1.5cm](ideal-name){\emph{Ideal}};
	
	\node[below of= ideal-name, yshift=1.5cm](ideal-entry){Entry};
	\node[below of= ideal-entry](ideal-center){};
	\node[below of= ideal-center](ideal-exit){Exit};
	
	\node[cut] (ideal-a) at ($(ideal-entry)!0.33!(ideal-exit)$){};
	\node[cut] (ideal-b) at ($(ideal-entry)!0.66!(ideal-exit)$){};
	
	\path[pil] (ideal-entry) edge[left] node {1} (ideal-a)
			   (ideal-a) edge[left] node {1} (ideal-b)
			   (ideal-b) edge[left] node {1} (ideal-exit);
	
\end{tikzpicture}
\end{figure}

\subsection{A block complexity}
A code block represents a single execution path. Statements in a code block are executed one by one. When a control flow enters a block, if no exception occurs, each statement is executed exactly once until a control flow exits a block. For such code block, the best approach to measure a complexity is an approach similar to a measuring complexity of code by the number of generated instructions, see section \ref{yield-complexity}.

The necessary adjustment is to replace the unit in form of an instruction for something corresponding in source code. Code blocks consist of statements. The most of statements generate zero or more instructions with constant execution time. Problematic statements are call expressions, because they effectively transfer an execution out of CFG. Therefore, they can be any complex. The used solution is to estimate their complexity. A block complexity is then sum of complexities of all statements in this block using values from the table \ref{yield-block}. A value is searched from top to bottom of the table for the first matching row. Values in the table were calculated in order to achieve expected results on some tested scenarios. The tool allows a user to change all of them by providing a custom configuration.

\begin{figure}[h!]
\caption{Complexities of statements in a block.}
\label{yield-block}
\vspace{0.5cm}
\renewcommand{\arraystretch}{1.1}
\centering
\begin{tabular}{ l | r }
  \cellcolor[gray]{0.9}Statement & \cellcolor[gray]{0.9} \\
  \textbf{Trivial call expression}\\Function body doesn't generate any instruction, body is empty. & 1 \\
  \textbf{Constant call expression}\\Function defined as constant expression. & 1 \\
  \textbf{Inlined call expression}\\Function is decided to be inlined by compiler. & 5 \\
  \cellcolor[gray]{0.9}\textbf{Call expression} & \cellcolor[gray]{0.9}25 \\
  \cellcolor[gray]{0.9}\textbf{Statement} & \cellcolor[gray]{0.9}1 \\
\end{tabular}
\end{figure}

\subsection{A path complexity}
With the definition of a code block complexity as a basic construction element of a code path, it is possible to define a code path complexity as well. But loops are problem and yet unclear definition of a path in CFG.

Loop bodies are evaluated as independent CFG making source CFG acyclic. When a path enters a node with a loop statement as a terminator, the analysis processes a body of a loop and creates a new path for every path that is created in a loop body. New paths behave as they would skip a loop body, but their complexity is sum of the source path complexity, block complexity and body path complexity multiplied by a predefined constant from the table \ref{yield-loop-const}. Values in the table were calculated in order to achieve expected results on tested scenarios. The analyser allows a user to change them by custom configuration.

\begin{figure}[h!]
\caption{Multipliers of loop body complexities.}
\label{yield-loop-const}
\vspace{0.5cm}
\renewcommand{\arraystretch}{1.1}
\centering
\begin{tabular}{ m{5cm} | r }
  \cellcolor[gray]{0.9}Statement & \cellcolor[gray]{0.9} \\
  \code{for} statement & 20 \\
  \code{while} statement & 25 \\
  \code{do} statement & 25 \\
\end{tabular}
\end{figure}

The path that would skip a loop body is omitted from the analysis. This path has a very low probability, but it is affecting results significantly.

The figure \ref{yield-loop} shows an example of a part of CFG with a \code{for} loop statement and \code{if} selection statement in a body of this loop. Numbers next to edges represent paths complexities and numbers in graph nodes represent blocks complexities. There is a single path with the complexity of 5 entering the node with the \code{for} statement terminator. The loop body itself contains two different paths with complexities of 2 and 3. Two paths leaving the block with \code{for} statement terminator have complexities of 46 and 47 calculated as \emph{\code{for} loop multiplier * body path complexity + entering path complexity + complexity of the block with a \code{for} statement terminator}.

\begin{center}
\emph{20 * 2 + 5 + 1 = 46}\\
\emph{20 * 3 + 5 + 1 = 47}
\end{center}

\begin{figure}[h!]
\centering
\vspace{0.5cm}
\begin{tikzpicture}[node distance=3.5cm]
	\tikzstyle{node} = [circle, draw, minimum width=17pt, inner sep=0pt]

	% Loop node
	\node[node](loop){1};
	\node[above right of=loop](entry){};
	\node[below right of=loop](exit){};
	
	\path[pil] (entry) edge[right] node {5} (loop)
	           (loop) edge[right] node {46, 66} (exit);
	
	\node[left of=loop, xshift=1.0cm](body){};
	\node[node, below of=body, yshift=2.0cm](b-entry){0};
	\node[node, above of=body, yshift=-2.0cm](b-exit){1};
	\node[node, left of=body, xshift=2.35cm](b1){1};
	\node[node, right of=body, xshift=-2.35cm](b2){2};
	
	\path[pil] (loop) edge[bend left=50, below] node {0} (b-entry)
	           (b-exit) edge[bend left=50, above] node {2, 3} (loop);
	           
	\path[pil] (b-entry) edge[bend left=20, left] node {0} (b1)
	           (b-entry) edge[bend right=20, right] node {0} (b2);
	           
	\path[pil] (b1) edge[bend left=20, left] node {1} (b-exit)
	           (b2) edge[bend right=20, right] node {2} (b-exit);
	
\end{tikzpicture}
\caption{A path passing through a node with the \code{for} loop statement terminator and a selection statement in the body.}
\label{yield-loop}
\end{figure}

\subsection{Additional block data}
The analyser needs to keep additional data to CFG when calculating paths complexities. Fortunately, each block in CFG has a unique identifier. Therefore, additional data for each block is stored in a map with a block identifier as the key.

Data about every path is stored for every block it passes. Every path has its own unique identifier. Because a lot of paths share their beginnings, information about their complexity from the Entry block to this block is shared as well in the structure with:

\begin{itemize}
\item{Set of path identifiers.}
\item{Complexity.}
\end{itemize}
Block data then consists of:
\begin{itemize}
\item{Set of path information.}
\item{Yield state of a block with three different states:}
	\begin{description}
	\item[No]{There is no yield call expression in this block.}
	\item[Planned]{The optimizer plans to put yield into this block.}
	\item[Present]{Source code already includes the yield call expression.}
	\end{description}
	\emph{Note}: Distinguish between present and planned states is to ease final code transformation.
\item{A map of a path identifier as the key and complexity as a value for blocks with a loop statement terminator. A map holds complexities of loop body paths.}
\end{itemize}

\subsection{A value of CFG}
The algorithm for the optimization works in the iterative way. It tries to inject yield calls to CFG to make it \textit{better} than source CFG. Such algorithm needs a value to quantify a CFG quality. The rest of the text refers to this value as \emph{goodness}.

The first idea to quantify quality was based on the simple principle that it should be preferred to have less paths, because of injecting the yield call increases their number, and more complex paths, to avoid too little execution times, but with a sort of \emph{penalty} for paths exceeding a threshold, see figure \ref{yield-penalty} where vertical lines represent code paths and their lengths represent their complexities. How this \emph{penalty} should be calculated and how it should affect result goodness of CFG has appeared to be problematic. What does it mean that there is a task running for a long time in a parallel environment? In the worst case, this task inhibits an execution of all other tasks. In an environment with the possibility to run 8 different tasks in parallel, it inhibits an execution of 7 instructions for each of its executed instruction. The first obvious drawback is that it is not scalable for different systems with a different number of parallel tasks. But it is not the crucial obstacle, because this value can be an input of the optimizer tool and a user can set it for his system. The second drawback is that the presented constant is for the worst case scenario, which is very rare, but it still can be adjusted to a different value that reflects the real slowdown better, again using the custom optimizer configuration.

The tested calculation of goodness with the \emph{penalty} approach was:

\begin{center}
$\sum_{paths}{complexity} - multiplier * \sum_{paths}{penalty}$
\end{center}

The reason why this approach has been discarded is because there are scenarios with expected results that the optimization method should have solved, but no value as $multiplier$ from the calculation could solve all of them.

\begin{figure}[h!]
\caption{The \emph{penalty} method to evaluate goodness.}
\label{yield-penalty}
\centering
\vspace{0.5cm}
\begin{tikzpicture}[node distance=2.0cm]
	
	\node(paths) at (0,0.5) {Paths};
	
	% Base
	\node(entry) at (-5.75,0) {Entry};
	\draw[line width=3pt] (-5,0) -- (5,0);
	
	% Threshold
	\node[below=of entry.east, anchor=east] (threshold) {Threshold};
	\draw[line width=1pt] (-5,-2) -- (5,-2);

	% Penalty	
	\node[below=of threshold.east, anchor=east, yshift=0.75cm] (penalty) {Penalty};

	% Tasks
	\draw[thick] (-4,0) -- (-4,-1.6);
	\draw[thick] (-3,0) -- (-3,-2.75);
	\draw[pattern=north west lines, pattern color=gray] (-3.1,-2.0) rectangle (-2.9,-2.75);
	\draw[thick] (-2,0) -- (-2,-2.23);
	\draw[pattern=north west lines, pattern color=gray] (-2.1,-2.0) rectangle (-1.9,-2.23);
	\draw[thick] (-1,0) -- (-1,-0.3);
	\draw[thick] ( 0,0) -- ( 0,-4.0);
	\draw[pattern=north west lines, pattern color=gray] (-0.1,-2.0) rectangle ( 0.1,-4.0);
	\draw[thick] ( 1,0) -- ( 1,-5.0);
	\draw[pattern=north west lines, pattern color=gray] ( 0.9,-2.0) rectangle ( 1.1,-5.0);
	\draw[thick] ( 2,0) -- ( 2,-1.75);
	\draw[thick] ( 3,0) -- ( 3,-1.1);
	\draw[thick] ( 4,0) -- ( 4,-4.2);
	\draw[pattern=north west lines, pattern color=gray] ( 3.9,-2.0) rectangle ( 4.1,-4.2);
\end{tikzpicture}
\end{figure}

Thinking back, the goal of the method was already described in the chapter introduction (\ref{yield-intro}) and there is no problem to apply it for the evaluation of CFG. Tasks execution times should be as balanced as possible. They should not be too low or too high. Now, it is enough to replace the concept of tasks for the concept of execution paths and ideal execution time for a threshold. Then, goodness is sum of distances from a threshold that represents ideal execution time. With this method, it is one less constant to handle and the calculated goodness value works well for tested scenarios. A bit confusing is the naming and the ordering. \emph{CFG with lower goodness is better than CFG with higher}.

Figure \ref{yield-distance} shows the described situation. Vertical lines are execution paths and their lengths represent their complexities. When comparing this figure with the figure \ref{yield-penalty}, the only difference is that this approach includes paths with a lower complexity than a threshold more into the calculation.

\begin{figure}[t!]
\centering
\vspace{0.5cm}
\begin{tikzpicture}[node distance=2.0cm]
	
	\node(paths) at (0,0.5) {Paths};
	
	% Base
	\node(entry) at (-5.75,0) {Entry};
	\draw[line width=3pt] (-5,0) -- (5,0);
	
	% Threshold
	\node[below=of entry.east, anchor=east] (threshold) {Threshold};
	\draw[line width=1pt] (-5,-2) -- (5,-2);

	% Tasks
	\draw[thick] (-4,0) -- (-4,-1.6);
	\draw[pattern=north west lines, pattern color=gray] (-4.1,-1.6) rectangle (-3.9,-2.0);
	\draw[thick] (-3,0) -- (-3,-2.75);
	\draw[pattern=north west lines, pattern color=gray] (-3.1,-2.0) rectangle (-2.9,-2.75);
	\draw[thick] (-2,0) -- (-2,-2.23);
	\draw[pattern=north west lines, pattern color=gray] (-2.1,-2.0) rectangle (-1.9,-2.23);
	\draw[thick] (-1,0) -- (-1,-0.3);
	\draw[pattern=north west lines, pattern color=gray] (-1.1,-0.3) rectangle (-0.9,-2.0);
	\draw[thick] ( 0,0) -- ( 0,-4.0);
	\draw[pattern=north west lines, pattern color=gray] (-0.1,-2.0) rectangle ( 0.1,-4.0);
	\draw[thick] ( 1,0) -- ( 1,-5.0);
	\draw[pattern=north west lines, pattern color=gray] ( 0.9,-2.0) rectangle ( 1.1,-5.0);
	\draw[thick] ( 2,0) -- ( 2,-1.75);
	\draw[pattern=north west lines, pattern color=gray] ( 1.9,-1.75) rectangle ( 2.1,-2.0);
	\draw[thick] ( 3,0) -- ( 3,-1.1);
	\draw[pattern=north west lines, pattern color=gray] ( 2.9,-1.1) rectangle ( 3.1,-2.0);
	\draw[thick] ( 4,0) -- ( 4,-4.2);
	\draw[pattern=north west lines, pattern color=gray] ( 3.9,-2.0) rectangle ( 4.1,-4.2);
\end{tikzpicture}
\caption{The \emph{distance from threshold} method to evaluate goodness.}
\label{yield-distance}
\end{figure}

\subsection{The algorithm}
With the metric for a quality of CFG, there is no missing information for a description of the iterative algorithm, see figure \ref{yield-algorithm}.

\begin{figure}[h!]
\caption{The algorithm for the yield complex optimization method.}
\label{yield-algorithm}
\begin{enumerate}
\item{\emph{cfg} = Build CFG data.}
\item{\emph{goodness} = Calculate goodness of \emph{cfg}.}
\item{\emph{temp\_cfg} = Run optimization step on \emph{cfg}.}
\item{\emph{temp\_goodness} = Calculate goodness of \emph{temp\_cfg}.}
\item{If \emph{temp\_goodness} < \emph{goodness} then}
	\begin{enumerate}[label=5.\arabic*.]
	\item{\emph{goodness} = \emph{temp\_goodness}.}
	\item{Swap \emph{cfg} with \emph{temp\_cfg}.}
	\item{Continue in step 3.}
	\end{enumerate}
\item{Else finish, \emph{cfg} is optimized.}
\end{enumerate}
\end{figure}

On the first look, the algorithm is very defensive. It does the optimization step, then it checks whether it is really better CFG. Yet, there is still a lot of work hidden in the \emph{optimization step} command.

\subsubsection{The analysis}
CFG is analysed and complexities are calculated using the depth-first search algorithm implemented by a function call recursion. The analysis has to handle yield calls in blocks, which can be already in code or are planned for an insertion by the optimizer.

Inputs of the analysis are CFG and a set of information about yield states of blocks represented as a pair of a block identifier and yield state. This set must contain information only for blocks with \emph{Planned} or \emph{Present} yield states. When data is built for the first time, the set with information about yield states is empty.

When the analysis finds the yield call expression in block statements, it ends the current path, stores its data in the block, and creates a new path starting in the block with a zero complexity. The same happens if there is information about any yield state in function input data. Then, block statements are not processed at all and yield information is copied from the input.

\subsubsection{Optimization step}
The only goal of the optimization step is to decrease goodness of CFG. The algorithm uses brute force to achieve that. At first, it collects all blocks where at least one path ends, i.e., the exit block and blocks with the \emph{Planned} or \emph{Present} yield state. Then,  it processes every block and calculates what happens if the yield call is placed into that block. A block with the best outcome has its yield state set to \emph{Planned}.

\subsection{Default threshold}
\label{yield-default}
A quadratic complexity is widely considered to be the threshold for being complex and performance demanding. Using values from tables \ref{yield-block} and \ref{yield-loop-const}, the default value for threshold is calculated as an execution of two inner \code{for} loops with two inlined, non-trivial, non-constant call expressions.

\begin{center}
\emph{20 * 20 * 2 * 25 = 20000}
\end{center}

\subsection{Code injection}
The last step of the optimization process is an injection of a yield call to blocks with the \emph{Planned} yield state. A block with such yield state can be empty, it can contain a single statement in a condition expression of a selection statement, or the right-hand side expression in a binary expression, or the else branch in a conditional expression, or any other language structure where it is hard to chain statements. An injection of a member function call expression to such location can be impossible or using tricks with the comma operator.

The easy solution is to find a compound statement that is as good candidate for an injection as the chosen block. An injection of a member call expression into compound statement is then simple and safe. The prefetch optimization method already does inject code into compound statements.

At first, the optimization method collects all compound statements in the function body compound statement\footnote{The function body compound statement is included in this set}. Then, it collects all blocks with the \emph{Planned} yield state. For every collected block, it checks all compound statements whether it can inject a yield call related to the block. For example, if it encounters the \code{for} statement and the block is equivalent to the incremental expression, a yield call is injected into the body compound statement. All special cases of the yield call injection are shown in the figure \ref{yield-injection}. A source of the arrow is the block with the \emph{Planned} yield state. A target is the place where the yield call is inserted.

\begin{figure}[h!]
\caption{An injection of the yield call for some special cases of statements.}
\label{yield-injection}
\centering
\vspace{0.5cm}
\begin{tikzpicture}[node distance=0.0cm]
	\tikzstyle{empty} = [rectangle, draw, thin, minimum width=2.0cm, minimum height=13pt, inner sep=0pt, rounded corners=3pt]
	
	\tikzstyle{yield} = [rectangle, draw, thin, minimum width=0.5cm, minimum height=13pt, inner sep=0pt, rounded corners=3pt]

	% If statement
	\node[yield](ifyield){};
	\node[below=15pt of ifyield.west, anchor=west](ifstmt){if/switch/while (};
	\node[empty, right=of ifstmt.east, anchor=west](ifcond){ cond };
	\node[right=of ifcond.east, anchor=west](ifstmtthen){) \{\}};
	
	\path[pil] (ifcond.north) edge[bend right=5] node {} (ifyield);
	
	% for statement
	\node[yield, below=1.5cm of ifstmt.west, anchor=west](foryield){};
	\node[below=15pt of foryield.west, anchor=west](forstmt){for (};
	
	\node[empty, right=of forstmt.east, anchor=west](forinit){ init };
	\node[right=of forinit.east, anchor=west](forinitsemi){; };
	
	\node[empty, right=of forinitsemi.east, anchor=west](forcond){ cond };
	\node[right=of forcond.east, anchor=west](forcondsemi){; };
	
	\node[empty, right=of forcondsemi.east, anchor=west](forinc){ inc };
	\node[right=of forinc.east, anchor=west](forincend){)};
	
	\node[below=15pt of forstmt.west, anchor=west](forlbracket){\{};
	\node[below=15pt of forlbracket.west, anchor=west, xshift=1cm](fordots){...};
	\node[yield, below=15pt of fordots.west, anchor=west](forbodyyield){};
	\node[below=15pt of forbodyyield.west, anchor=west, xshift=-1cm](forrbracket){\}};
	
	\path[pil] (forinit.north) edge[bend right=15] node {} (foryield)
	           (forcond.north) edge[bend right=10] node {} (foryield)
	           (forinc.south) edge[bend left=20] node {} (forbodyyield);

\end{tikzpicture}
\end{figure}

\section{Further improvements}
The current state of the optimization method can be still improved by a lot. Some indications about further improvements are already mentioned through the thesis text. The goal was to stabilize the current implementation and postpone major code updates.

\subsection{Runtime checks}
As an example, if auto-vectorization back-end optimizers cannot prove that operations in a loop body do not overlap in a compilation, they generate runtime checks and both versions of a loop, original and vectorized. Although there is nothing to \emph{prove} mentioned in the method description, there is a lot of \emph{guessing}. Using runtime checks, it would be possible to handle suspicious cases which are not handled with the current algorithm. For example, a single loop with a complex body with complexity just below the threshold, or any repetition of the case shown on the figure \ref{yield-wrong1}.

\subsection{Probabilities}
The optimization method considers that all paths in CFG have the same probability. It is simplification. For example, functions have often multiple checks of their arguments on the beginning of their bodies, but the analysis can assume that these branches will not be taken in a majority of function calls because inputs are expected to be correct. What probabilities should be assigned to paths is a very complex task with size greatly exceeding size of a single thesis. Developers of branch predictors on modern processors confront a similar task. Some of their ideas could be reused for the static analysis, but the most of mechanisms used for a prediction are based on runtime information.

An assignment of probabilities to paths would change the calculation of the goodness value.

\subsection{Identify producers}
In the introduction to the optimization method (\ref{yield-intro}), there are mentioned multiple drawbacks of long tasks executions. One of them is a possible congestion of framework internal structures. The analysis can assign more \emph{weight} to paths that produce data for other tasks in order to ease their yield. Loops producing data deserves more recognition than loops performing calculations.

\subsection{Deep analysis}
Probably the simplest case of an improvement for the optimizer is a deeper analysis of statements in CFG blocks. Complexities of a call expressions are guessed, but some of them can be calculated more precise. All categories of call expressions can be analysed deeper if the analysis has an access to the body of a callee. It would be unbearable to count in function CFG, but some heuristic based on a callee definition can be helpful. The possible result of such heuristic can be in form of the depth of the most nested loop.

\section{Scenarios}


\subsection{Two sequential tasks}
The first scenario to test is the simplest one testing two sequential tasks in function body. Code snippet with complexity of default threshold (\ref{yield-default}) is considered to be a task. The expected outcome is yield between these two tasks.

\begin{lstlisting}[caption={The first scenario with two sequential \textit{tasks}.}]
for (int i = 0; i < 10; ++i) {
    for (int j = 0; j < 10; ++j) {
        complex_function();
        complex_function();
    }
}
yield(); // injected by algorithm.
for (int k = 0; k < 10; ++k) {
    for (int l = 0; l < 10; ++l) {
        complex_function();
        complex_function();
    }
}
\end{lstlisting}

\begin{figure}[h!]
\caption{CFG of the first scenario with block chosen to yield by algorithm.}
\label{yield-insertion}
\centering
\vspace{0.5cm}
\begin{tikzpicture}[node distance=0.30cm]
	\tikzstyle{node} = [circle, draw, minimum width=20pt, inner sep=0pt]

	\node[node](15){15};
	\node[node, below =of 15](14){14};
	\node[node, below =of 14](13){13};
	\node[node, below left =of 13, xshift=-3cm](12){12};
	\node[node, below right =of 13, xshift=3cm, fill=gray!40](7){7};
	
	\node[node, below =of 12](11){11};
	\node[node, below left =of 11](10){10};
	\node[node, below right =of 11](8){8};
	\node[node, below =of 10](9){9};
	
	\node[node, below =of 7](6){6};
	\node[node, below left =of 6](5){5};
	\node[node, below right =of 6](0){0};
	
	\node[node, below =of 5](4){4};
	\node[node, below left =of 4](3){3};
	\node[node, below right =of 4](1){1};
	\node[node, below =of 3](2){2};
	
	\path[->] (15) edge node {} (14)
		(14) edge node {} (13)
		(13) edge node {} (12)
		(13) edge node {} (7)
		(12) edge node {} (11)
		(11) edge node {} (10)
		(11) edge node {} (8)
		(10) edge node {} (9)
		(9) edge node {} (11)
		(8) edge node {} (13)
		(7) edge node {} (6)
		(6) edge node {} (5)
		(6) edge node {} (0)
		(5) edge node {} (4)
		(4) edge node {} (3)
		(4) edge node {} (1)
		(3) edge node {} (2)
		(2) edge node {} (4)
		(1) edge node {} (6);
\end{tikzpicture}
\end{figure}

\subsection{Complex branch}
The first task from the first scenario is moved to branch followed by block with function call. Expected yield is found by algorithm.

\begin{lstlisting}[caption={The second scenario with complex branch.}]
static bool cond = true;
if (cond) {
    for (int i = 0; i < 10; ++i) {
        for (int j = 0; j < 10; ++j) {
            complex_function();
            complex_function();
        }
    }
    yield(); // injected by algorithm.
    complex_function();
}
// the second task.
\end{lstlisting}

\subsection{Complex loop body}
Task is moved to loop body. Algorithm yields every body iteration.

\begin{lstlisting}[caption={The third scenario with complex loop body.}]
for (int i = 0; i < 10; ++i)
{
    for (int j = 0; j < 10; ++j)
    {
        for (int k = 0; k < 10; ++k)
        {
            complex_function();
            complex_function();
        }
    }
    yield(); // injected by algorithm.
}
\end{lstlisting}